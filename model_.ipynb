{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the needed dependencies\n",
    "import import_ipynb\n",
    "import numpy as np #for matrix calculations\n",
    "import csv\n",
    "import os\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense,Activation, ZeroPadding2D, Flatten, Conv2D, BatchNormalization\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import np_utils, print_summary\n",
    "import pandas as pd #for converting csv into our dataframe\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\Lenovo\\Project 1 data.csv\") #reading our csv data\n",
    "dataset=np.array(data) #converting the data into an array\n",
    "np.random.shuffle(dataset) #shuffling the dataset\n",
    "X=dataset #x rows\n",
    "Y=dataset #y columns\n",
    "X=X[:, 0:1024]\n",
    "Y=Y[:, 1024]\n",
    "\n",
    "X_train=X[0:70000, :] #splitting the dataset into training and testing datasets\n",
    "X_train=X_train/255 #normalising train\n",
    "X_test=X[70000:72001, :]\n",
    "X_test=X_test/255 #normalising test\n",
    "\n",
    "#reshaping\n",
    "Y=Y.reshape(Y.shape[0], 1)\n",
    "Y_train=Y[0:70000, :]\n",
    "Y_train=Y_train.T #taking transpose \n",
    "Y_test=Y[70000:72001, :]\n",
    "Y_test=Y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples=70000\n",
      "number of testing examples=2000\n",
      "X_train shape:(70000, 1024)\n",
      "Y_train shape:(1, 70000)\n",
      "X_test shape:(2000, 1024)\n",
      "Y_test shape:(1, 2000)\n"
     ]
    }
   ],
   "source": [
    "print(\"number of training examples=\" + str(X_train.shape[0])) #printing our created dataset's information \n",
    "print(\"number of testing examples=\" + str(X_test.shape[0]))\n",
    "print(\"X_train shape:\" + str(X_train.shape))\n",
    "print(\"Y_train shape:\" + str(Y_train.shape))\n",
    "print(\"X_test shape:\" + str(X_test.shape))\n",
    "print(\"Y_test shape:\" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x=32 #image size of 32x32(height and width)\n",
    "image_y=32\n",
    "\n",
    "train_y=np_utils.to_categorical(Y_train) #converting into vectors\n",
    "test_y=np_utils.to_categorical(Y_test)\n",
    "train_y=train_y.reshape(train_y.shape[1], train_y.shape[2])\n",
    "test_y=test_y.reshape(test_y.shape[1], test_y.shape[2])\n",
    "X_train=X_train.reshape(X_train.shape[0], image_x, image_y, 1)\n",
    "X_test=X_test.reshape(X_test.shape[0], image_x, image_y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(70000, 32, 32, 1)\n",
      "Y_train shape:(70000, 37)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\" + str(X_train.shape)) #printing the shape of train x and train y\n",
    "print(\"Y_train shape:\" + str(train_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building model\n",
    "def keras_model(image_x, image_y): #function1\n",
    "    num_of_classes=37\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5, 5), input_shape=(image_x, image_y, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding='same'))\n",
    "    model.add(Flatten()) #flattening vector into a vector\n",
    "    model.add(Dense(num_of_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    filepath=\"devanagari.h5\" #saving model after building\n",
    "    checkpoint1=ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list=[checkpoint1]\n",
    "    \n",
    "    return model, callbacks_list #returning to the calling variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70000 samples, validate on 2000 samples\n",
      "Epoch 1/2\n",
      "70000/70000 [==============================] - 279s 4ms/step - loss: 0.7365 - acc: 0.7913 - val_loss: 0.2571 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92100, saving model to devanagari.h5\n",
      "Epoch 2/2\n",
      "70000/70000 [==============================] - 249s 4ms/step - loss: 0.2145 - acc: 0.9354 - val_loss: 0.1738 - val_acc: 0.9565\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92100 to 0.95650, saving model to devanagari.h5\n",
      "CNN error :4.35%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 37)                9509      \n",
      "=================================================================\n",
      "Total params: 61,605\n",
      "Trainable params: 61,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, callbacks_list=keras_model(image_x, image_y) #calling the function\n",
    "model.fit(X_train, train_y, validation_data=(X_test, test_y), epochs=2, batch_size=64, callbacks=callbacks_list)\n",
    "scores=model.evaluate(X_test, test_y, verbose=0)\n",
    "print(\"CNN error :%.2f%%\" % (100-scores[1]*100)) #printing error\n",
    "print_summary(model) #printing the details of the model\n",
    "model.save('devanagari.h5') #saving the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
